{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning - Gout Emergency Department Chief Complaint\n",
    " ### The goal of this project is the answer the question:   </np><i>Is the patient potentially suffering from Gout?</i> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scope of this project is corpora from the Deep South.  The demographics of the population from which they were derived are 54% female, and 46% male, 55% Black, 40% White, 2% Hispanic, and 1% Asian. Age distribution was 5% between ages 1-20 years, 35% between ages 21-40 years, 35% between ages 41-60 years, 20% between ages 61-80 years, and 5% between ages 81-100 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The data is extracted in csv format from the MIMIC-III (Medical Information Mart for Intensive Care III) database.  Details can be found at https://physionet.org/content/emer-complaint-gout/1.0/.   Acces to the database may be requested at (https://mimic.physionet.org/gettingstarted/access/). \n",
    "\n",
    "The data provided by the MIMIC database consists of 2 corpora of free text collected by the triage nurse and recorded as the \"Chief Complaint\".  Each complaint contains up to 282 characters in length and was collected from 2019 to 2020 at an academic medical center in the Deep South.  The 2019 corpora, \"GOUT-CC-2019-CORPUS\", consists of 300 chief complaints selected by the presence of the keyword \"gout\". The 2020 corpora, \"GOUT-CC-2020-CORPUS\" contains 8037 chief complaints collected from a single month in 2020. The chief complaints included in both corpora were selected based on the presence of the keyword \"gout\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T21:50:53.023861Z",
     "start_time": "2021-04-20T21:50:53.003138Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "syn2019 = pd.read_csv('Data/GOUT-CC-2019-CORPUS-SYNTHETIC.csv')\n",
    "syn2020 = pd.read_csv('Data/GOUT-CC-2020-CORPUS-SYNTHETIC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Data Description**\n",
    "* 2 csv files\n",
    "    * 2019 : 300 records\n",
    "    * 2020 : 8037 records\n",
    "    * Identical layouts and formats: all text, 3 columns\n",
    "    <br><br>\n",
    "* 3 Columns:  [\"Chief Complaint\", \"Predict\", \"Consensus\"]\n",
    "    * <b>Chief Complaint:</b> \n",
    "        * text format\n",
    "        * up to 282 Chars\n",
    "        * nurse recorded patient complaint\n",
    "    * <b>Predict:</b> \n",
    "        * text format\n",
    "        * single char ('-','U','Y','N')\n",
    "        * prediction of Gout by the ER Physician\n",
    "    * <b>Consensus:</b> \n",
    "        * textformat\n",
    "        * single char ('-','U','Y','N')\n",
    "        * determination of Gout by the Endocrinologist\n",
    "    <br>\n",
    "* \n",
    "          - : Null\n",
    "          U : Unknonw\n",
    "          Y : Yes\n",
    "          N : Gout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Chief Complaint Predict Consensus\n",
      "0  \"been feeling bad\" last 2 weeks & switched BP ...       N         -\n",
      "1  \"can't walk\", reports onset at 0830 am. orient...       Y         N\n",
      "2  \"dehydration\" Chest hurts, hips hurt, cramps P...       Y         Y\n",
      "3  \"gout flare up\" L arm swelling x 1 week. denie...       Y         Y\n",
      "4  \"heart racing,\"dyspnea, and orthopnea that has...       N         -\n"
     ]
    }
   ],
   "source": [
    "print(syn2019.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Chief Complaint Predict Consensus\n",
      "0  \"I dont know whats going on with my head, its ...       N         -\n",
      "1  \"i've been depressed for a few weeks now, i'm ...       N         -\n",
      "2  Altercation while making arrest, c/o R hand pa...       N         N\n",
      "3  Cut on L upper thigh wtih saw. Bleeding contro...       N         N\n",
      "4   Dysuria x1 week. hx: hysterectomy, gerd, bipolar       N         -\n"
     ]
    }
   ],
   "source": [
    "print(syn2020.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine the 2 files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8437, 3)\n"
     ]
    }
   ],
   "source": [
    "# Combine the files into 1 dataframe\n",
    "df = pd.concat([syn2019, syn2020], axis=0).reset_index(drop=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review records for null value '-' in the files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U     156\n",
      "N    8168\n",
      "-       2\n",
      "Y     111\n",
      "Name: Predict, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Predict'].value_counts(sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U      16\n",
      "N     350\n",
      "-    7976\n",
      "Y      95\n",
      "Name: Consensus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Consensus'].value_counts(sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are 2 records that have null values in both the Predict and Consensus column and will not provide any predictive quality and so will be removed during cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Chief Complaint Predict Consensus\n",
      "7799  Right lower back pain that radiates down leg t...       -         -\n",
      "7857  pain to posterior upper leg x 3 days, seen at ...       -         -\n"
     ]
    }
   ],
   "source": [
    "print( df[(df.Consensus == '-') & (df.Predict == '-')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "    * Remove records that contain null values in both of the Predict and Consensus columns.\n",
    "    * Change all chars to lowercase\n",
    "    * Remove punctuation\n",
    "    * Remove words containing numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove records with double 'null' values, records with '-' in both Consensus and Predict.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8435, 3)\n"
     ]
    }
   ],
   "source": [
    "df = df[(df.Consensus != '-') | (df.Predict != '-')]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert to loercase, remove punctuation and words containing numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chief Complaint</th>\n",
       "      <th>Predict</th>\n",
       "      <th>Consensus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>been feeling bad last weeks switched bp medica...</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cant walk reports onset at am oriented x aorti...</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dehydration chest hurts hips hurt cramps pmh h...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gout flare up l arm swelling x week denies any...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heart racingdyspnea and orthopnea that has bee...</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8432</th>\n",
       "      <td>stepped on a nail at home with right foot pain...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8433</th>\n",
       "      <td>i was having a breakdown rt stress and depres...</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8434</th>\n",
       "      <td>i tried to jump in front of a car pt states sh...</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8435</th>\n",
       "      <td>abdominal pain x week denies pmh</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8436</th>\n",
       "      <td>rashsores across body infection ro left thumb ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8435 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Chief Complaint Predict Consensus\n",
       "0     been feeling bad last weeks switched bp medica...       N         -\n",
       "1     cant walk reports onset at am oriented x aorti...       Y         N\n",
       "2     dehydration chest hurts hips hurt cramps pmh h...       Y         Y\n",
       "3     gout flare up l arm swelling x week denies any...       Y         Y\n",
       "4     heart racingdyspnea and orthopnea that has bee...       N         -\n",
       "...                                                 ...     ...       ...\n",
       "8432  stepped on a nail at home with right foot pain...       N         N\n",
       "8433   i was having a breakdown rt stress and depres...       N         -\n",
       "8434  i tried to jump in front of a car pt states sh...       N         -\n",
       "8435                   abdominal pain x week denies pmh       N         -\n",
       "8436  rashsores across body infection ro left thumb ...       N         N\n",
       "\n",
       "[8435 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    text=text.lower()                                                 # change all chars to lowercase    \n",
    "    text=re.sub('[%s]' % re.escape(string.punctuation), '', text)     # remove punctuations\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)                                # remove numbers\n",
    "    return text\n",
    "\n",
    "\n",
    "df['Chief Complaint'] = df['Chief Complaint'].apply(lambda x:clean_text(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below we create a Corpus for analysis and a Document-Term Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_data = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(\"[\\w']+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Chief Complaint'] = df['Chief Complaint'].apply(lambda x: tokenizer.tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [feeling, bad, last, weeks, switched, bp, medi...\n",
       "1    [cant, walk, reports, onset, oriented, x, aort...\n",
       "2    [dehydration, chest, hurts, hips, hurt, cramps...\n",
       "3    [gout, flare, l, arm, swelling, x, week, denie...\n",
       "4    [heart, racingdyspnea, orthopnea, getting, wor...\n",
       "Name: Chief Complaint, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Chief Complaint'] = df['Chief Complaint'].apply(lambda x : remove_stopwords(x))\n",
    "df['Chief Complaint'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [feeling, bad, last, week, switched, bp, medic...\n",
       "1       [cant, walk, report, onset, oriented, x, aorti...\n",
       "2       [dehydration, chest, hurt, hip, hurt, cramp, p...\n",
       "3       [gout, flare, l, arm, swelling, x, week, denie...\n",
       "4       [heart, racingdyspnea, orthopnea, getting, wor...\n",
       "                              ...                        \n",
       "8432    [stepped, nail, home, right, foot, painful, di...\n",
       "8433                  [breakdown, rt, stress, depression]\n",
       "8434    [tried, jump, front, car, pt, state, psych, me...\n",
       "8435              [abdominal, pain, x, week, denies, pmh]\n",
       "8436    [rashsores, across, body, infection, ro, left,...\n",
       "Name: Chief Complaint, Length: 8435, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Chief Complaint'].apply(lambda x: word_lemmatizer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Store the prepped data in a dataframe for Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Pickle the clean dataframe\n",
    "df.to_pickle(\"df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Document-Term Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "vectorized = vectorizer.fit_transform(matrix_data['Chief Complaint'])\n",
    "vectored_data = pd.DataFrame.sparse.from_spmatrix(vectorized, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aain</th>\n",
       "      <th>aao</th>\n",
       "      <th>aaox</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abcess</th>\n",
       "      <th>abcessed</th>\n",
       "      <th>abcessess</th>\n",
       "      <th>...</th>\n",
       "      <th>zofran</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zoned</th>\n",
       "      <th>zpac</th>\n",
       "      <th>zpack</th>\n",
       "      <th>zpak</th>\n",
       "      <th>zquil</th>\n",
       "      <th>zyprexa</th>\n",
       "      <th>zyrtec</th>\n",
       "      <th>zyrtecd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8430</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8431</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8434</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8435 rows × 8243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aaa  aain  aao  aaox  ab  abandon  abcess  abcessed  abcessess  ...  \\\n",
       "0      0    0     0    0     0   0        0       0         0          0  ...   \n",
       "1      0    0     0    0     0   0        0       0         0          0  ...   \n",
       "2      0    0     0    0     0   0        0       0         0          0  ...   \n",
       "3      0    0     0    0     0   0        0       0         0          0  ...   \n",
       "4      0    0     0    0     0   0        0       0         0          0  ...   \n",
       "...   ..  ...   ...  ...   ...  ..      ...     ...       ...        ...  ...   \n",
       "8430   0    0     0    0     0   0        0       0         0          0  ...   \n",
       "8431   0    0     0    0     0   0        0       0         0          0  ...   \n",
       "8432   0    0     0    0     0   0        0       0         0          0  ...   \n",
       "8433   0    0     0    0     0   0        0       0         0          0  ...   \n",
       "8434   0    0     0    0     0   0        0       0         0          0  ...   \n",
       "\n",
       "      zofran  zoloft  zoned  zpac  zpack  zpak  zquil  zyprexa  zyrtec  \\\n",
       "0          0       0      0     0      0     0      0        0       0   \n",
       "1          0       0      0     0      0     0      0        0       0   \n",
       "2          0       0      0     0      0     0      0        0       0   \n",
       "3          0       0      0     0      0     0      0        0       0   \n",
       "4          0       0      0     0      0     0      0        0       0   \n",
       "...      ...     ...    ...   ...    ...   ...    ...      ...     ...   \n",
       "8430       0       0      0     0      0     0      0        0       0   \n",
       "8431       0       0      0     0      0     0      0        0       0   \n",
       "8432       0       0      0     0      0     0      0        0       0   \n",
       "8433       0       0      0     0      0     0      0        0       0   \n",
       "8434       0       0      0     0      0     0      0        0       0   \n",
       "\n",
       "      zyrtecd  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "8430        0  \n",
       "8431        0  \n",
       "8432        0  \n",
       "8433        0  \n",
       "8434        0  \n",
       "\n",
       "[8435 rows x 8243 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectored_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle for Analysis\n",
    "vectored_data.to_pickle(\"vectored_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
